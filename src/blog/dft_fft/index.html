<!DOCTYPE html>

<html>
<head>
	<title>{{ title }}</title>
	<link rel="stylesheet" type="text/css" href="/style_blue.css">
	<meta charset="UTF-8">
</head>
<body>
	{% include "header.html" %}
	<article>
		<h1>{{ title }}</h1>
		
		<p>This writing aims to be an introduction to the Discrete Fourier Transform (DFT) for those without any prior knowledge of regular Fourier series or transforms.</p>
		
		<h2>Motivation</h2>
		
		<p>The motivation behind Fourier transforms is pretty simple: <i>you want to find out what sinusoidal components your signal has, and retrieve their respective amplitudes and frequencies</i>. This is indeed simple if you have already worked with such stuff, but it raises a lot of questions for a complete beginner. What is a signal? Why do I want to find its frequencies? Why do I use sines and cosines to accomplish this? To make everything clear, let's answer those questions. Or you can <a href="#skip">skip</a> this part.</p>
		
		<p><b>Signal</b>s are usually divided into four categories by two main characteristics. They can be discrete or continous in time (the domain) and similarly have discrete or continous values (the codomain). For now, making a distinction in the codomain serves no purpose, so we are left with two groups.</p>
		
		<p>In practice you have discrete signals, for example measurements from a sensor with a timestamp and a numeric value. The <span class="plt_blue">blue dots</span> mark such a signal with five measurement points. These points can be easily represented programatically by an array with pairs of numbers as items.</p>
		
		<img id="signal" src="media/signal_lowfreq.png">
		
		<p><span class="mono">[(0.4, 1.17), (1.15, 2.74), (1.9, 2.84), (2.65, 1.42), (3.4, -0.77)]</span></p>
		
		<p>The <span class="plt_red">red line</span> represents a more abstract signal (3*sin(x) in this case). It is defined for every x, but dealing with concrete values gets harder as the functions composing the signal get more complex. At first glance it may seem that the blue signal samples the red one, as it fits perfectly in those points, but <a class="hoverbutton" onmouseover="hi_freq()" onmouseout="lo_freq()">why would that be the case</a>?</p>
		
		<p>It seems abstract functions would serve a purpose in inter- and extrapolating values, if they would be unequivocally expressible. Without diving into the realm of interpolation we can say that there won't be a bijection between discrete and continous signals, but also that the first signal <i>clearly</i> fits our measurements more, where 'clearly' remains an ambigous term for now.</p>
		
		<p>There are also two things worth mentioning about the <span class="plt_blue">blue signal</span>:</p>
		
		<ul>
			<li>The time scale is completely arbitrary. There is no real meaning behind t=0, so we can shift the whole signal left by 0.4. When we are dealing with only one signal, there is no reason not fix its start point at zero time as leaving the offset at 0.4 would only make our calculations more complicated.</li>
			<li>Samples are taken periodically at a fixed rate. That might <a href="https://en.wikipedia.org/wiki/Non-uniform_discrete_Fourier_transform">not always</a> be the case, but still is most of the time so using this simplification should be fine for now. As said above, the time scale is arbitrary, so we can rescale the whole signal to have its samples taken at positive (and zero) integer time values. Of course you are probably dealing with physical quantities, so the time scale <i>is</i> important and should not be completely discarded, but more on that later.</li>
		</ul>
		
		<p>So, our signal looks like this now:</p>
		
		<img src="media/signal_norm.png">
		
		<p>Also the array form is trivialized even more, no need to store indices anymore:</p>
		
		<p><span class="mono">[1.17, 2.74, 2.84, 1.42, -0.77]</span></p>
		
		<p>And lastly, <b>Why do I use sines and cosines?</b> First, they are periodic functions. You might say a <a href="https://en.wikipedia.org/wiki/Square_wave">square wave</a> is periodic as well and way easier to make calculations with. But these signals are often pushed through integration and derivation steps, and it is rare to find such function that can survive these methods without minor alterations. Sine derives into cosine, and vica versa with a factor of -1, thus making repeated derivation return the original function after four steps. <a href="https://en.wikipedia.org/wiki/Exponential_function">Exponential</a> and <a href="https://en.wikipedia.org/wiki/Hyperbolic_function">hyperbolic</a> functions also have this property (and are closely related), but they are not periodic in the real domain. A flat constant zero function satisfies both properties, but is completely uninteresting.</p>
		
		<h2 id="skip">Synthesis and analysis</h2>
		
		<p class="disclaimer">The thought line of the following section (and some code examples) was largely based on <a href="https://github.com/AllenDowney/ThinkDSP">ThinkDSP</a> (chapter 6 and 7), but with some alterations, whenever I felt more clarification is needed.</p>
		
		<p>Our building blocks are cosine signals, which have a <a href="https://en.wikipedia.org/wiki/Frequency">frequency</a> (f) and an amplitude (A) as parameters (and a phase which we conviniently ignore for now).</p>
		
		{{ formula("simple_cosine.tex", 32) }}
		
		<p>The 2 * π * f part is often abbreviated as ω (greek small omega), but we'll stick with the 2πf notation.</p>
		
		<p>We can build more complex signals by summing some of these cosines (with different frequencies and amplitudes).</p>
		
		{{ formula("sum_cosine.tex", 20) }}
		
		<p id="complexcosine">As the example shows, even the sum of three cosines can result in complex-looking functions:</p>
		
		<img src="media/sum_cosine_concrete.svg"> <!-- TODO solve multi colored TeX rendering -->
		
		<img src="media/synthesis_example.png">
		
		<p>Instead of preceiving this signal as a sum, we can treat it as an <b>inner product</b> of two vectors, one being the amplitudes, and the other the cosine terms.</p>
		
		{{ formula("synthesis_vectors.tex", 28) }}
		
		<p>What do we gain from that? Nothing, as long as we are plugging our <i>x</i>-es to this function one by one. But generally, if this signal is a generator, we are going to take more than one sample. With multiple <i>x</i>-es and frequencies the cosine vector expands into a <b>matrix</b> and now we have a matrix-vector multiplication.</p>
		
		{{ formula("synthesis_matrix.tex", 24) }} <!-- TODO extra space added at the right somewhy -->
		
		<p>Maybe it is more clear with a different notation (hover on result elements to see the inner products):</p>
		
		<figure>
			<canvas id="synthesis_matrix"></canvas>
		</figure>
		
		<p>This step is called <b>synthesis</b> where the result signal is built from our base components. The reverse of this is <b>analysis</b> where we know the frequencies and the result signal (the samples in our case) and the variables under question are the amplitudes. If you are familiar with <a href="https://en.wikipedia.org/wiki/Gaussian_elimination">Gaussian elimination</a>, you already know the next step, if not, read it up. Basically we have three equatations for three unknown variables (A1, A2, A3). The cosine terms might look scary, but since all of their variables are constant, the terms themselves will be constant as well. We can sample a continous signal as many times as we want, but it is easy to see that we need at least as many samples as many frequencies we have; and that further samples add no information to our system of equatations.
		
		<p>Well, the above sentence is not entirely true, there are edge cases, where even though we have three equatations, the system won't be solvable. If a column is full of zeroes, or two columns are equal, our solution will be ambigous. This translates nicely into the world of signals, if two our frequencies sync with the sampling frequency, they are going to measure the same value each time. With a sampling rate of 1 and two integer frequencies, we will never find a solution. Also a full zero column tells us nothing about the amplitude, as seen below:</p>
		
		<figure>
			<video autoplay loop>
				<source src="media/analysis_zeros.mp4" type="video/mp4">
			</video>
		</figure>
		
		<p>Instead of solving a linear system of equatations each time, we can get the same result by taking the <b>inverse</b> of this cosine matrix. The edge cases discussed above correspond to the determinant being zero, thus the inverse of the matrix not existing, but otherwise this is the way to go. To be honest, this is the most important concept in this whole article, and if you can understand the Gaussian elimination or the inverse method, you understood DFT as well, as from now, only the details of this matrix and the inverse calculation methods will change.</p>
		
		<p>You can verify this with a few lines of code. A python example below using the values <a href="#complexcosine">seen before</a>:</p>
		
		{{ code("analysis_example.py") }}
		
		<p><b>But hey!</b> - you might ask - <b>how do I find the frequencies as well? It is sure nice to be able to calculate the amplitudes, <i>if I already know what frequencies my signal has</i>, but that's not the case!</b> Yes, but before we make a choice on the frequencies to test for, there is another, even more serious problem.</p>
		
		<p>In the beginning of this section I made the not explained decision of solely using cosines as our building blocks instead of sines or both. What happens if we try to approximate a sum of sines by cosines? Let's modify our last example slightly:</p>
		
		{{ formula("sum_sine_concrete.tex", 20) }}
		
		<p>There is no reason to sample the <span class="plt_red">resulting signal</span> at zero time, as it will always be zero there. Don't worry, in that case we'll just take our <span class="plt_blue">samples</span> at t = {1, 2, 3}.</p>
		
		<img src="media/analysis_sine.png">
		
		<p>This results in S = <span class="mono">[1.25, 1.66, 3.30]</span>
		
		{{ code("analysis_sine_pt1.py", "python") }}
		
		<p>And now doing the analysis with cosines</p>
		
		{{ code("analysis_sine_pt2.py", "python") }}
		
		<p>What we get back from this is A_calc = <span class="mono">[3.64, 2.41, -3.06]</span>. Not even close.</p>
		
		<h2>Exponentials</h2>
		
		<p>The first naïve idea would be: <i>Well, why don't we use both?</i> Naïve ideas are not necessarily bad ideas, so let's see how this turns out. Our building blocks are now sums of sine and cosine functions.</p>
		
		{{ formula("expo_sin_cos_1.tex", 24) }}
		
		<p>We can normalize A and B, by dividing them with the square root of the sum of the two terms squared</p>
		
		{{ formula("expo_sin_cos_2.tex", 24, amsmath=False) }}
		
		<p>Let's use <i>C</i> as a shorthand for {{ formula("expo_sin_cos_3.tex", 18, inline=True, amsmath=False) }}, and since the sum of <i>A/C</i> and <i>B/C</i> squared is 1 now, we can find a φ (greek phi) such as</p>
		
		{{ formula("expo_sin_cos_4.tex", 24, amsmath=False) }}
		
		{{ formula("expo_sin_cos_5.tex", 24, amsmath=False) }}
		
		<p>Dividing the second equatation with the first, the <i>C</i>s cancel out and we are left with a nicer formula</p>
		
		{{ formula("expo_sin_cos_6.tex", 24, amsmath=False) }}
		
		<p>And now we can get the value of φ by plugging <i>B/A</i> into the <a href="https://en.wikipedia.org/wiki/Inverse_trigonometric_functions">inverse</a> of tangent (also don't forget to check if <i>A</i> is zero). Our signal looks like this now:<p>
		
		{{ formula("expo_sin_cos_7.tex", 24) }}
		
		<p>Multiplied by <i>C</i> what we have right now is an <a href="https://en.wikipedia.org/wiki/List_of_trigonometric_identities#Angle_sum_and_difference_identities">identity</a>, namely the cosine of the difference of two angles.</p>
		
		{{ formula("expo_sin_cos_8.tex", 24) }}
		
		<p>We could do some rearrangement since cosine is an even function. Also we have shown (not rigorously) that with just a sine and a cosine, we are able to express any sinusoid shifted with a phase φ. There are also more intuitive ways to reach this conclusion. Cosine is an <b>even</b> function, and even functions can be used to analyse even signals, and the same can be said for sine, except it is <b>odd</b> and is useful for odd signals. And since you <a href="https://math.stackexchange.com/questions/5274/how-do-i-divide-a-function-into-even-and-odd-sections">can divide any signal into even and odd sections</a>, you can analyse both parts by using only sines or cosines.</p>
		
		<p>For me, the geometrical view was the most intuitive. We can treat <span class="mat_cyan_700">sine</span> and <span class="mat_green_700">cosine</span> as <i>projections</i> of a simple, two-dimensional circular rotation.</p>
		
		<figure>
			<canvas id="expo_sin_cos"></canvas>
		</figure>
		
		<p>We can represent this system, the red dot with a single parameter, namely the <span class="mat_yellow_900">angle</span>, and than define a function <b>rot</b>, that accepts a number, and spits out its cosine and sine as a pair.</p>
		
		{{ formula("exp_rot.tex", 24) }}
		
		<p>If you are familiar with <b>complex numbers</b>, the exponential form does the same and probably makes more sense to you than my arbitrarily defined function. Otherwise you are probably wondering where the hell did <i>e</i> and <i>j</i> come from, but don't worry about them; substitute <i>rot()</i> in your head. Furthermore, you might have seen this formula but with <i>i</i> instead of <i>j</i>, it is just a matter of notation which symbol to use.</p>
		
		{{ formula("exp_form.tex", 24) }}
		
		
		<p>Using complex numbers has a few advantages:</p>
		
		<ul>
			<li>Multiplying a complex number with a real number scales the complex number, but keeps the angle.</li>
			<img src="media/expo_scale.png">
			<li>Multiplying two rotations (complex number with length one) yields a third one with its angle being the sum of of the two original angles due to the exponential identities.</li>
			<img src="media/expo_angle.png">
		</ul>
		
		<p>Usually when multiplying two complex numbers, scaling and rotation both take place.</p>
		
		<p>But how all of this helps us in practice? Well, take a step back. We have shown that from a sine and cosine pair we can handle all kinds of phases. The reverse is also true: for any phase, a sine and cosine pair is sufficient. This increases the width of our matrix M by twice, and to keep our system of equatations solvable, we'll need to take twice as many samples now. Remember, for each frequency component, we have now two unknowns to solve: the sine and cosine, or in other terms, the amplitude and the angle.</p>
		
		<figure>
			<canvas id="synthesis_sin_cos"></canvas>
		</figure>
		
		<p>Add a few phases to our last example:</p>
		
		<img src="media/expo_sin_cos_example.svg"> <!-- TODO coloring -->
		
		<p>With six sample points from 0 to 5 our signal looks like this:<p>
		
		<img src="media/expo_sin_cos_example_plot.png">
		
	</article>
	<script src="script.js"></script>
</body>
</html>
